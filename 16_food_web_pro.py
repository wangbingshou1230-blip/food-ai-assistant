import streamlit as st
import requests
import re
import pdfplumber
import pandas as pd
import plotly.graph_objects as go
import edge_tts
import asyncio
from io import BytesIO

# --- 1. é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(
    page_title="FoodMaster æ™ºèƒ½å·¥ä½œå°",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. ğŸ” ç™»å½•éªŒè¯ ---
def check_password():
    if st.session_state.get("password_correct", False):
        return True
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.title("ğŸ”’ FoodMaster Pro ç™»å½•")
        st.markdown("---")
        password = st.text_input("è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password")
        if st.button("ğŸš€ ç™»å½•ç³»ç»Ÿ"):
            correct_password = st.secrets.get("APP_PASSWORD", "123456")
            if password == correct_password:
                st.session_state["password_correct"] = True
                st.rerun()
            else:
                st.error("âŒ å¯†ç é”™è¯¯")
    return False

if not check_password():
    st.stop()

# ==================================================
#  é…ç½®ä¸å·¥å…·å‡½æ•°
# ==================================================

if "DEEPSEEK_API_KEY" not in st.secrets:
    st.error("âš ï¸ é…ç½®ç¼ºå¤±ï¼šè¯·åœ¨ Secrets ä¸­æ·»åŠ  DEEPSEEK_API_KEY")
    st.stop()
API_KEY = st.secrets["DEEPSEEK_API_KEY"]

# --- AI è°ƒç”¨ ---
def call_deepseek_chat(messages):
    url = "https://api.deepseek.com/chat/completions"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
    try:
        with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
            response = requests.post(url, headers=headers, json={
                "model": "deepseek-chat",
                "messages": messages,
                "stream": False
            })
            if response.status_code == 200:
                return response.json()['choices'][0]['message']['content']
            else:
                return f"Error: {response.status_code} - {response.text}"
    except Exception as e:
        return f"è¯·æ±‚å¼‚å¸¸: {e}"

def call_deepseek_once(system_prompt, user_input):
    return call_deepseek_chat([
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_input}
    ])

# --- è¯­éŸ³åˆæˆ (TTS) å·¥å…·å‡½æ•° (æ–°!) ---
async def generate_speech(text, voice):
    """å¼‚æ­¥ç”Ÿæˆè¯­éŸ³"""
    communicate = edge_tts.Communicate(text, voice)
    # å°†éŸ³é¢‘æ•°æ®å†™å…¥å†…å­˜ BytesIOï¼Œé¿å…äº§ç”Ÿä¸´æ—¶æ–‡ä»¶
    mp3_fp = BytesIO()
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            mp3_fp.write(chunk["data"])
    mp3_fp.seek(0)
    return mp3_fp

# --- å…¶ä»–å·¥å…· ---
@st.cache_data(ttl=3600)
def get_realtime_news():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        url = "https://top.baidu.com/board?tab=realtime"
        resp = requests.get(url, headers=headers)
        titles = re.findall(r'class="c-single-text-ellipsis">(.*?)</div>', resp.text)
        return [t.strip() for t in titles if len(t) > 4][:10]
    except Exception as e:
        return [f"æŠ“å–å¼‚å¸¸: {e}"]

def extract_text_from_pdf(file):
    try:
        with pdfplumber.open(file) as pdf:
            text = ""
            for page in pdf.pages[:5]: 
                text += page.extract_text() + "\n"
            return text
    except:
        return ""

def plot_sensory_radar(product_name, trend):
    categories = ['ç”œåº¦', 'é…¸åº¦', 'è‹¦åº¦', 'å’¸åº¦', 'é²œåº¦']
    if "é…¸å¥¶" in product_name: values = [3, 4, 1, 0, 2]
    elif "å’–å•¡" in product_name: values = [2, 3, 5, 0, 1]
    elif "èŒ¶" in product_name: values = [1, 2, 4, 0, 3]
    elif "éº»è¾£" in product_name: values = [1, 1, 1, 4, 5]
    else: values = [3, 2, 1, 1, 2]
    if "0ç³–" in trend: values[0] = 1
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=values, theta=categories, fill='toself', name=product_name, line_color='#FF4B4B'
    ))
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 5])), showlegend=False, margin=dict(t=20, b=20, l=40, r=40))
    return fig

# --- ä¾§è¾¹æ  ---
st.sidebar.title("ğŸ§¬ FoodMaster Pro")
st.sidebar.caption("é£Ÿå“ç¡•å£«çš„æ•°å­—åŒ–è§£å†³æ–¹æ¡ˆ")

app_mode = st.sidebar.selectbox(
    "é€‰æ‹©å·¥ä½œæ¨¡å¼",
    ["ğŸ”¬ R&D ç ”å‘ä¸åˆè§„ (å¯¹è¯ç‰ˆ)", "ğŸ¬ è‡ªåª’ä½“å†…å®¹çŸ©é˜µ", "âš™ï¸ äº‘ç«¯æ•°æ®çœ‹æ¿"]
)

# ==================================================
# æ¨¡å— 1: R&D ç ”å‘ (ä¿æŒ v3.0 ä¸å˜)
# ==================================================
if app_mode == "ğŸ”¬ R&D ç ”å‘ä¸åˆè§„ (å¯¹è¯ç‰ˆ)":
    st.title("ğŸ”¬ æ™ºèƒ½ç ”å‘ä¸æ³•è§„åŠ©æ‰‹")
    
    if "messages_law" not in st.session_state:
        st.session_state["messages_law"] = [{"role": "system", "content": "ä½ æ˜¯ä¸€åèµ„æ·±çš„é£Ÿå“æ³•è§„ä¸“å‘˜ã€‚"}]
    
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ æ³•è§„æ™ºèƒ½å¯¹è¯", "ğŸ“„ æ™ºèƒ½æ–‡æ¡£ Chat", "ğŸ“Š æ–°å“ç ”å‘å¯è§†åŒ–"])

    with tab1:
        for msg in st.session_state["messages_law"]:
            if msg["role"] != "system":
                with st.chat_message(msg["role"]): st.markdown(msg["content"])
        
        if prompt := st.chat_input("è¾“å…¥åˆè§„é—®é¢˜..."):
            st.session_state["messages_law"].append({"role": "user", "content": prompt})
            with st.chat_message("user"): st.markdown(prompt)
            response = call_deepseek_chat(st.session_state["messages_law"])
            st.session_state["messages_law"].append({"role": "assistant", "content": response})
            with st.chat_message("assistant"): st.markdown(response)
        
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
            st.session_state["messages_law"] = [{"role": "system", "content": "ä½ æ˜¯ä¸€åèµ„æ·±çš„é£Ÿå“æ³•è§„ä¸“å‘˜ã€‚"}]
            st.rerun()

    with tab2:
        st.subheader("ğŸ“„ æ™ºèƒ½æ–‡æ¡£å¯¹è¯")
        uploaded_files = st.file_uploader("ä¸Šä¼  PDF", type="pdf", accept_multiple_files=True)
        if "messages_doc" not in st.session_state: st.session_state["messages_doc"] = []
        if "pdf_context" not in st.session_state: st.session_state["pdf_context"] = ""

        if uploaded_files:
            if st.button("ğŸ“¥ è¯»å–æ–‡æ¡£"):
                content = ""
                for file in uploaded_files: content += f"\n--- {file.name} ---\n{extract_text_from_pdf(file)}\n"
                st.session_state["pdf_context"] = content
                st.success("è¯»å–å®Œæ¯•")
                st.session_state["messages_doc"] = [{"role": "system", "content": f"åŸºäºä»¥ä¸‹å†…å®¹å›ç­”:\n{content[:8000]}"}]

        if st.session_state["pdf_context"]:
            for msg in st.session_state["messages_doc"]:
                if msg["role"] != "system":
                    with st.chat_message(msg["role"]): st.markdown(msg["content"])
            if prompt := st.chat_input("æé—®æ–‡æ¡£..."):
                st.session_state["messages_doc"].append({"role": "user", "content": prompt})
                with st.chat_message("user"): st.markdown(prompt)
                response = call_deepseek_chat(st.session_state["messages_doc"])
                st.session_state["messages_doc"].append({"role": "assistant", "content": response})
                with st.chat_message("assistant"): st.markdown(response)

    with tab3:
        st.subheader("ğŸ’¡ æ–°å“æ¦‚å¿µç”Ÿæˆ")
        c1, c2 = st.columns(2)
        with c1: base_product = st.text_input("åŸºåº•", "0ç³–é…¸å¥¶")
        with c2: target_user = st.text_input("äººç¾¤", "å‡è„‚å…š")
        trend = st.selectbox("è¶‹åŠ¿", ["è¯é£ŸåŒæº", "0ç³–0å¡", "é«˜è›‹ç™½", "æ¸…æ´æ ‡ç­¾"])
        if st.button("ç”Ÿæˆ"):
            col_text, col_chart = st.columns([3, 2])
            with col_text: st.markdown(call_deepseek_once("ç”Ÿæˆæ–°å“æ¦‚å¿µä¹¦", f"{base_product} {target_user} {trend}"))
            with col_chart: st.plotly_chart(plot_sensory_radar(base_product, trend))

# ==================================================
# æ¨¡å— 2: è‡ªåª’ä½“å†…å®¹çŸ©é˜µ (æ–°å¢ TTS é…éŸ³å®¤)
# ==================================================
elif app_mode == "ğŸ¬ è‡ªåª’ä½“å†…å®¹çŸ©é˜µ":
    st.title("ğŸ¬ è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿäº§å·¥å‚")
    
    # å°†åŸæ¥çš„å¸ƒå±€æ‹†åˆ†ä¸º Tabsï¼ŒåŠ å…¥é…éŸ³åŠŸèƒ½
    tab_script, tab_voice = st.tabs(["ğŸ“ æ™ºèƒ½è„šæœ¬ç”Ÿæˆ", "ğŸ™ï¸ AI é…éŸ³å®¤ (TTS)"])

    # --- Tab 1: è„šæœ¬ç”Ÿæˆ (åŸæ¥çš„åŠŸèƒ½) ---
    with tab_script:
        col_hot, col_gen = st.columns([1, 2])
        with col_hot:
            if st.button("ğŸ”„ åˆ·æ–°çƒ­æœ"): st.cache_data.clear()
            hot_list = get_realtime_news()
            selected_hot = st.radio("é€‰æ‹©çƒ­ç‚¹ï¼š", hot_list, index=None)
            if selected_hot: st.session_state['selected_topic'] = selected_hot

        with col_gen:
            topic = st.text_input("é€‰é¢˜", value=st.session_state.get('selected_topic', ''))
            c1, c2 = st.columns(2)
            with c1: type_ = st.selectbox("ç±»å‹", ["è¾Ÿè°£", "æµ‹è¯„", "æ­ç§˜"])
            with c2: style = st.selectbox("é£æ ¼", ["å®æ‹", "åŠ¨æ¼«", "èµ›åš"])
            
            if st.button("ğŸš€ ç”Ÿæˆåˆ†é•œè„šæœ¬"):
                if topic:
                    # æç¤ºç”¨æˆ·å¤åˆ¶æ–‡æ¡ˆ
                    st.info("ğŸ’¡ æç¤ºï¼šç”Ÿæˆåï¼Œè¯·å¤åˆ¶è¡¨æ ¼ä¸­çš„'å£æ’­æ–‡æ¡ˆ'åˆ°ã€AI é…éŸ³å®¤ã€‘ç”Ÿæˆè¯­éŸ³ã€‚")
                    prompt = f"æˆ‘æ˜¯ç§‘æ™®åšä¸»ã€‚é€‰é¢˜ï¼š{topic}ã€‚ç±»å‹ï¼š{type_}ã€‚é£æ ¼ï¼š{style}ã€‚è¾“å‡ºMarkdownåˆ†é•œè¡¨ã€‚"
                    st.markdown(call_deepseek_once(prompt, topic))

    # --- Tab 2: AI é…éŸ³å®¤ (æ–°åŠŸèƒ½) ---
    with tab_voice:
        st.subheader("ğŸ™ï¸ æ–‡å­—è½¬è¯­éŸ³ (Text to Speech)")
        st.caption("åŸºäº Edge-TTS æŠ€æœ¯ï¼Œå…è´¹ç”Ÿæˆé«˜è´¨é‡ AI è¯­éŸ³ï¼Œæ— éœ€å½•éŸ³è®¾å¤‡ã€‚")
        
        text_input = st.text_area("åœ¨æ­¤ç²˜è´´è¦æœ—è¯»çš„æ–‡æ¡ˆ", height=150, placeholder="ä¾‹å¦‚ï¼šå„ä½åŒå­¦å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ä½ ä»¬çš„é£Ÿå“å­¦é•¿...")
        
        # å£°éŸ³é€‰æ‹© (æŒ‘é€‰äº†å‡ ä¸ªå¥½å¬çš„ä¸­æ–‡éŸ³è‰²)
        voice_option = st.selectbox("é€‰æ‹©éŸ³è‰²", [
            "zh-CN-XiaoxiaoNeural (å¥³å£°-æ¸©æš–äº²åˆ‡)",
            "zh-CN-YunxiNeural (ç”·å£°-ç¨³é‡æ´»æ³¼)",
            "zh-CN-YunjianNeural (ç”·å£°-æ–°é—»æ’­éŸ³)",
            "zh-CN-XiaoyiNeural (å¥³å£°-æ°”åœºå…¨å¼€)"
        ])
        
        # æå– voice id
        voice_id = voice_option.split(" ")[0]
        
        if st.button("ğŸ§ å¼€å§‹ç”Ÿæˆè¯­éŸ³"):
            if text_input:
                with st.spinner("AI æ­£åœ¨å½•éŸ³æ£šé‡Œæœ—è¯»..."):
                    # è¿è¡Œå¼‚æ­¥ç”Ÿæˆ
                    try:
                        mp3_audio = asyncio.run(generate_speech(text_input, voice_id))
                        st.success("âœ… ç”ŸæˆæˆåŠŸï¼ç‚¹å‡»ä¸‹æ–¹æ’­æ”¾æˆ–ä¸‹è½½")
                        st.audio(mp3_audio, format="audio/mp3")
                    except Exception as e:
                        st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
            else:
                st.warning("è¯·å…ˆç²˜è´´æ–‡æ¡ˆï¼")

# ==================================================
# æ¨¡å— 3: äº‘ç«¯çœ‹æ¿
# ==================================================
elif app_mode == "âš™ï¸ äº‘ç«¯æ•°æ®çœ‹æ¿":
    st.title("âš™ï¸ è‡ªåŠ¨åŒ–ç³»ç»Ÿç›‘æ§")
    st.info("äº‘ç«¯ä»»åŠ¡ï¼šdaily_task.py æ­£åœ¨ GitHub æœåŠ¡å™¨ä¸Šæ¯æ—¥ 08:00 è¿è¡Œ")
    if st.button("ğŸ“² å‘é€æµ‹è¯•æ¨é€"):
        if "BARK_SERVER" in st.secrets:
            try:
                requests.get(f"{st.secrets['BARK_SERVER']}/{st.secrets['BARK_DEVICE_KEY']}/æµ‹è¯•/ç½‘é¡µç«¯æŒ‡ä»¤")
                st.success("âœ… æ¨é€æˆåŠŸ")
            except: st.error("å¤±è´¥")