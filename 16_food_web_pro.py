import streamlit as st
import requests
import re
import pdfplumber
import pandas as pd
import plotly.graph_objects as go
import edge_tts
import asyncio
import json
import easyocr
import numpy as np
from datetime import datetime
from io import BytesIO
from PIL import Image
from supabase import create_client, Client

# --- RAG 2.0 æ ¸å¿ƒç»„ä»¶ ---
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_pinecone import PineconeVectorStore

# --- 1. é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(
    page_title="FoodMaster æ™ºèƒ½å·¥ä½œå°",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. ğŸ” ç™»å½•éªŒè¯ ---
def check_password():
    if st.session_state.get("password_correct", False):
        return True
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.title("ğŸ”’ FoodMaster Pro ç™»å½•")
        st.markdown("---")
        password = st.text_input("è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password")
        if st.button("ğŸš€ ç™»å½•ç³»ç»Ÿ"):
            correct_password = st.secrets.get("APP_PASSWORD", "123456")
            if password == correct_password:
                st.session_state["password_correct"] = True
                st.rerun()
            else:
                st.error("âŒ å¯†ç é”™è¯¯")
    return False

if not check_password():
    st.stop()

# ==================================================
#  äº‘ç«¯æ•°æ®åº“ (Supabase)
# ==================================================
supabase = None
try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    @st.cache_resource
    def init_supabase():
        return create_client(SUPABASE_URL, SUPABASE_KEY)
    supabase = init_supabase()
except Exception as e:
    st.sidebar.warning("âš ï¸ Supabase é…ç½®æœªç”Ÿæ•ˆ")

def save_to_db(record_type, title, content):
    if not supabase:
        st.error("æ•°æ®åº“æœªè¿æ¥")
        return
    try:
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M")
        data = {
            "type": record_type,
            "title": title,
            "content": content,
            "timestamp": current_time
        }
        supabase.table("records").insert(data).execute()
        st.sidebar.success(f"â˜ï¸ å·²äº‘ç«¯å½’æ¡£: {title[:10]}...")
    except Exception as e:
        st.sidebar.error(f"ä¿å­˜å¤±è´¥: {e}")

def get_history(record_type=None):
    if not supabase: return []
    try:
        query = supabase.table("records").select("*").order("id", desc=True).limit(20)
        if record_type:
            query = query.eq("type", record_type)
        response = query.execute()
        return response.data
    except Exception as e:
        return []

# ==================================================
#  RAG 2.0 å‘é‡åº“è¿æ¥ (Pinecone)
# ==================================================
@st.cache_resource
def get_vector_store():
    if "PINECONE_API_KEY" not in st.secrets:
        return None
    try:
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        vectorstore = PineconeVectorStore(
            index_name="food-standards",
            embedding=embeddings,
            pinecone_api_key=st.secrets["PINECONE_API_KEY"]
        )
        return vectorstore
    except Exception as e:
        return None

# ==================================================
#  DeepSeek API & Tools
# ==================================================
if "DEEPSEEK_API_KEY" not in st.secrets:
    st.error("âš ï¸ Secrets ç¼ºå¤± DEEPSEEK_API_KEY")
    st.stop()
API_KEY = st.secrets["DEEPSEEK_API_KEY"]

def call_deepseek_advanced(messages, model_type="chat"):
    url = "https://api.deepseek.com/chat/completions"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
    model = "deepseek-reasoner" if model_type == "reasoner" else "deepseek-chat"
    try:
        r = requests.post(url, headers=headers, json={"model": model, "messages": messages, "stream": False})
        if r.status_code == 200:
            res = r.json()['choices'][0]['message']
            return res.get('reasoning_content', ''), res.get('content', '')
        return None, f"Error: {r.status_code}"
    except Exception as e: return None, str(e)

def call_deepseek_once(sys, user):
    _, c = call_deepseek_advanced([{"role":"system","content":sys},{"role":"user","content":user}],"chat")
    return c

async def generate_speech(text, voice):
    communicate = edge_tts.Communicate(text, voice)
    mp3 = BytesIO()
    async for chunk in communicate.stream():
        if chunk["type"] == "audio": mp3.write(chunk["data"])
    mp3.seek(0)
    return mp3

@st.cache_resource
def load_ocr(): return easyocr.Reader(['ch_sim','en'], gpu=False)

def ocr_image(file):
    try:
        return " ".join(load_ocr().readtext(np.array(Image.open(file)), detail=0))
    except Exception as e: return f"OCR Error: {e}"

def generate_eln(messages):
    t = datetime.now().strftime("%Y-%m-%d %H:%M")
    rpt = f"# ELN Report\nTime: {t}\n\n"
    for m in messages:
        if m['role']!='system': rpt += f"## {m['role']}\n{m['content']}\n\n"
    return rpt

def plot_nutrition_pie(data_dict):
    if not data_dict: data_dict = {"ç¢³æ°´": 0, "è›‹ç™½": 0, "è„‚è‚ª": 0}
    fig = go.Figure(data=[go.Pie(labels=list(data_dict.keys()), values=list(data_dict.values()), hole=.3)])
    fig.update_layout(margin=dict(t=20,b=20,l=20,r=20), showlegend=True)
    return fig

def plot_radar(name, trend):
    vals = [3, 2, 1, 1, 2]
    if "é…¸å¥¶" in name: vals = [3, 4, 1, 0, 2]
    elif "å’–å•¡" in name: vals = [2, 3, 5, 0, 1]
    
    if "0ç³–" in trend: vals[0] = max(0, vals[0]-2)
    if "é«˜è›‹ç™½" in trend: vals[4] = min(5, vals[4]+1)
    
    fig = go.Figure(go.Scatterpolar(r=vals, theta=['ç”œåº¦', 'é…¸åº¦', 'è‹¦åº¦', 'å’¸åº¦', 'é²œåº¦'], fill='toself', name=name))
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 5])), showlegend=False, margin=dict(t=20,b=20,l=40,r=40))
    return fig

# ==================================================
#  ä¸»ç•Œé¢é€»è¾‘
# ==================================================
st.sidebar.title("ğŸ§¬ FoodMaster Pro")
st.sidebar.caption("v11.4 | ä½“éªŒä¼˜åŒ–ç‰ˆ") 
app_mode = st.sidebar.selectbox("å·¥ä½œæ¨¡å¼", ["ğŸ”¬ R&D ç ”å‘ä¸­å¿ƒ", "ğŸ¬ è‡ªåª’ä½“å·¥å‚", "ğŸ—„ï¸ äº‘ç«¯æ¡£æ¡ˆåº“", "âš™ï¸ äº‘ç«¯ç›‘æ§"])

# --------------------------------------------------
#  MODE 1: R&D ç ”å‘ä¸­å¿ƒ
# --------------------------------------------------
if app_mode == "ğŸ”¬ R&D ç ”å‘ä¸­å¿ƒ":
    st.title("ğŸ”¬ æ™ºèƒ½ç ”å‘ä¸æ³•è§„åŠ©æ‰‹")
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ§  è‡ªç”±å¤§è„‘é…ç½®")
    # UXä¼˜åŒ–ï¼šæ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·è¿™é‡Œçš„è®¾ç½®åªç®¡å“ªé‡Œ
    model_choice = st.sidebar.radio("å¯¹è¯/æ£€ç´¢æ¨¡å‹", ["ğŸš€ V3 æé€Ÿç‰ˆ", "ğŸ§  R1 æ·±åº¦æ€è€ƒ"], 0)
    st.sidebar.caption("â„¹ï¸ æ³¨ï¼šé…æ–¹è®¡ç®—ã€é£é™©åˆ†æç­‰ä¸“ä¸šä»»åŠ¡å°†è‡ªåŠ¨å¼ºåˆ¶ä½¿ç”¨ R1 ä»¥ç¡®ä¿ç²¾ç¡®æ€§ï¼›æ–°å“ç”Ÿæˆç­‰åˆ›æ„ä»»åŠ¡è‡ªåŠ¨ä½¿ç”¨ V3ã€‚")
    
    current_model = "reasoner" if "R1" in model_choice else "chat"

    # åŸºç¡€ Prompt
    strict_prompt = """
    ä½ æ˜¯ä¸€åä¸¥è°¨çš„é£Ÿå“æ³•è§„åˆè§„ä¸“å®¶ã€‚æ ¸å¿ƒåŸåˆ™ï¼šã€ä¾æ®äº‹å®ï¼Œæ‹’ç»å¹»è§‰ã€‘ã€‚
    1. å¼•ç”¨æ ‡å‡†ï¼šå¿…é¡»æ˜ç¡®å¼•ç”¨å…·ä½“æ ‡å‡†å·ï¼ˆå¦‚ GB 2760-2024ï¼‰ã€‚
    2. ä¿å®ˆå›ç­”ï¼šä¸ç¡®å®šè¯·å›ç­”â€œéœ€æ ¸å®â€ï¼Œä¸¥ç¦ç¼–é€ ã€‚
    """
    if "msg_law" not in st.session_state:
        st.session_state["msg_law"] = [{"role": "system", "content": strict_prompt}]

    # ä¾§è¾¹æ ä¿å­˜
    if len(st.session_state["msg_law"]) > 1:
        st.sidebar.markdown("---")
        report = generate_eln(st.session_state["msg_law"])
        st.sidebar.download_button("ğŸ“¥ å¯¼å‡º MD", report, "ELN.md")
        if st.sidebar.button("ğŸ’¾ å½’æ¡£å¯¹è¯"):
            q = next((m['content'] for m in st.session_state["msg_law"] if m['role']=='user'), "è®°å½•")
            save_to_db("ELN", f"å¯¹è¯: {q[:10]}", report)

    # 5å¤§åŠŸèƒ½åŒº
    tabs = st.tabs(["ğŸ’¬ æ³•è§„å¯¹è¯", "ğŸ§ª æ™ºèƒ½é…æ–¹", "ğŸ“¸ è§†è§‰åˆ†æ", "ğŸ§  è¡Œä¸šå¤§è„‘(RAG)", "ğŸ“Š æ–°å“æ¦‚å¿µ"])

    # --- Tab 1: æ³•è§„å¯¹è¯ ---
    with tabs[0]:
        st.caption(f"å½“å‰æ¨¡å¼ï¼š{'ğŸ§  R1 æ·±åº¦æ€è€ƒ' if current_model == 'reasoner' else 'ğŸš€ V3 æé€Ÿå“åº”'} (è·Ÿéšä¾§è¾¹æ è®¾ç½®)")
        for m in st.session_state["msg_law"]:
            if m['role']!='system':
                with st.chat_message(m['role']):
                    if "reasoning" in m: st.expander("ğŸ§  æ€ç»´é“¾ (CoT)").markdown(m["reasoning"])
                    st.markdown(m['content'])
                    if m['role'] == 'assistant':
                        st.caption("ğŸ›¡ï¸ æ ¸å®é“¾æ¥ï¼š")
                        c1, c2 = st.columns(2)
                        with c1: st.link_button("ğŸ”— é£Ÿå“ä¼™ä¼´ç½‘", "http://www.foodmate.net/standards/")
                        with c2: st.link_button("ğŸ”— å«å¥å§”", "https://ssp.nhc.gov.cn/database/standards/list.html")

        if p:=st.chat_input("è¾“å…¥åˆè§„é—®é¢˜"):
            st.session_state["msg_law"].append({"role":"user","content":p})
            with st.chat_message("user"): st.markdown(p)
            with st.chat_message("assistant"):
                with st.spinner("AI æ­£åœ¨æ£€ç´¢æ³•è§„åº“ä¸é€»è¾‘æ¨ç†ä¸­..."):
                    r, a = call_deepseek_advanced(st.session_state["msg_law"], current_model)
                if r: st.expander("ğŸ§  æ€ç»´é“¾ (CoT)").markdown(r)
                st.markdown(a)
                st.session_state["msg_law"].append({"role":"assistant","content":a,"reasoning":r})

    # --- Tab 2: æ™ºèƒ½é…æ–¹ ---
    with tabs[1]:
        st.subheader("ğŸ§ª æ™ºèƒ½é…æ–¹è®¡ç®—å™¨")
        st.caption("ğŸ”’ å·²è‡ªåŠ¨é”å®šï¼šDeepSeek-R1 (æ·±åº¦æ€è€ƒæ¨¡å¼) | åŸå› ï¼šç¡®ä¿é…æ–¹é€†å‘ä¸è¥å…»è®¡ç®—çš„æ•°å­¦ç²¾ç¡®æ€§")
        txt = st.text_area("è¾“å…¥é…æ–¹", height=100)
        
        if st.button("ğŸ§® å¯åŠ¨é…æ–¹å¼•æ“"):
            with st.spinner("R1 æ­£åœ¨é€†å‘æ‹†è§£é…æ–¹ç»“æ„..."):
                sys = "ä½ æ˜¯ä¸€åé…æ–¹å·¥ç¨‹å¸ˆã€‚è¯·æå–åŸæ–™ç™¾åˆ†æ¯”ï¼Œè®¡ç®—è¥å…»æˆåˆ†ï¼Œå¹¶è¿›è¡ŒGB2760åˆè§„é¢„è­¦ã€‚è¾“å‡ºJSONå’Œè¯¦ç»†åˆ†æã€‚"
                r, a = call_deepseek_advanced([{"role":"system","content":sys},{"role":"user","content":txt}], "reasoner")
                st.session_state["formula_res_a"] = a
                st.session_state["formula_res_r"] = r
                st.session_state["formula_txt"] = txt
        
        if "formula_res_a" in st.session_state:
            c1, c2 = st.columns([3, 2])
            with c1:
                if st.session_state.get("formula_res_r"): 
                    st.expander("ğŸ§  è®¡ç®—é€»è¾‘").markdown(st.session_state["formula_res_r"])
                st.markdown(st.session_state["formula_res_a"])
            with c2:
                plot_data = {"ç¢³æ°´åŒ–åˆç‰©": 12, "è›‹ç™½è´¨": 3.5, "è„‚è‚ª": 4.0, "æ°´/å…¶ä»–": 80.5}
                st.plotly_chart(plot_nutrition_pie(plot_data))
            
            st.markdown("---")
            if st.button("ğŸ’¾ äº‘ç«¯ä¿å­˜é…æ–¹"): 
                save_to_db("FORMULA", f"é…æ–¹: {st.session_state['formula_txt'][:10]}", st.session_state["formula_res_a"])

    # --- Tab 3: OCR ---
    with tabs[2]:
        st.subheader("ğŸ“¸ é…æ–™è¡¨æ‰«æ")
        st.caption("ğŸ”’ å·²è‡ªåŠ¨é”å®šï¼šDeepSeek-R1 (æ·±åº¦æ€è€ƒæ¨¡å¼) | åŸå› ï¼šé˜²æ­¢ OCR è¯†åˆ«é”™è¯¯åŠæ·»åŠ å‰‚é£é™©æ¼åˆ¤")
        f = st.file_uploader("ä¼ å›¾", ["jpg","png"])
        if f:
            st.image(f, width=300, caption="åŸå›¾é¢„è§ˆ")
            if st.button("ğŸ‘ï¸ å¼€å§‹è¯†åˆ«"):
                with st.spinner("æ­£åœ¨è¿›è¡Œ OCR..."):
                    txt = ocr_image(f)
                st.success("OCR æå–å®Œæˆ")
                with st.spinner("R1 æ­£åœ¨åˆ†æ..."):
                    r, a = call_deepseek_advanced([{"role":"user","content":f"åˆ†æé…æ–™è¡¨é£é™©:{txt}"}], "reasoner")
                
                st.session_state["ocr_txt"] = txt
                st.session_state["ocr_res_a"] = a
                st.session_state["ocr_res_r"] = r

                st.session_state["msg_law"].append({"role":"user","content":f"[OCR]{txt}"})
                st.session_state["msg_law"].append({"role":"assistant","content":a})

            if "ocr_res_a" in st.session_state:
                st.code(st.session_state["ocr_txt"], language='text')
                st.markdown("### ğŸ›¡ï¸ é£é™©è¯„ä¼°æŠ¥å‘Š")
                if st.session_state.get("ocr_res_r"):
                    st.expander("ğŸ§  è¯„ä¼°é€»è¾‘").markdown(st.session_state["ocr_res_r"])
                st.markdown(st.session_state["ocr_res_a"])
                st.info("ğŸ’¡ æç¤ºï¼šè¯¥è®°å½•å·²è‡ªåŠ¨åŒæ­¥åˆ°ã€æ³•è§„å¯¹è¯ã€‘Tab ä¸­ã€‚")

    # --- Tab 4: è¡Œä¸šå¤§è„‘ ---
    with tabs[3]:
        st.subheader("ğŸ§  è¡Œä¸šå¤§è„‘ï¼šå…¨é‡æ³•è§„æ£€ç´¢ (Pinecone)")
        st.caption(f"å½“å‰æ¨¡å¼ï¼š{'ğŸ§  R1 æ·±åº¦æ€è€ƒ' if current_model == 'reasoner' else 'ğŸš€ V3 æé€Ÿå“åº”'} (è·Ÿéšä¾§è¾¹æ è®¾ç½®)")
        st.info("ğŸ’¡ å·²è¿æ¥ Pinecone å‘é‡çŸ¥è¯†åº“ã€‚æ— éœ€ä¸Šä¼  PDFï¼Œç›´æ¥æé—®å³å¯æ£€ç´¢å·²å…¥åº“çš„æ•°ç™¾ä»½å›½æ ‡ã€‚")
        
        vector_store = get_vector_store()
        
        if not vector_store:
            st.warning("âš ï¸ æœªæ£€æµ‹åˆ° PINECONE_API_KEY")
        else:
            query = st.text_input("è¾“å…¥ä½ è¦æŸ¥è¯¢çš„æ³•è§„é—®é¢˜")
            
            if st.button("ğŸ” æ·±åº¦æ£€ç´¢"):
                if not query:
                    st.warning("è¯·è¾“å…¥é—®é¢˜")
                else:
                    with st.spinner("æ­£åœ¨ Pinecone å‘é‡æµ·ä¸­æœå¯»..."):
                        docs = vector_store.similarity_search(query, k=3)
                        context_str = "\n\n".join([f"ã€æ¥æºï¼š{d.metadata.get('source', 'æœªçŸ¥')}ã€‘\n{d.page_content}" for d in docs])
                    
                    with st.spinner("DeepSeek R1 æ­£åœ¨æ¨ç†..."):
                        prompt = f"ä½ æ˜¯ä¸€åé£Ÿå“æ³•è§„ä¸“å®¶ã€‚åŸºäºä»¥ä¸‹ã€å‚è€ƒæ–‡æ¡£ã€‘å›ç­”é—®é¢˜ã€‚\n\nã€å‚è€ƒæ–‡æ¡£ã€‘ï¼š\n{context_str}\n\né—®é¢˜ï¼š{query}"
                        r, a = call_deepseek_advanced([{"role":"user","content":prompt}], current_model)
                    
                    st.session_state["rag_res_a"] = a
                    st.session_state["rag_res_r"] = r
                    st.session_state["rag_context"] = context_str
                    st.session_state["rag_query"] = query

            if "rag_res_a" in st.session_state:
                with st.expander(f"ğŸ“š è¯æ®æ¥æº ({st.session_state.get('rag_query', '')})"):
                    st.markdown(st.session_state["rag_context"])
                
                if st.session_state.get("rag_res_r"):
                    st.expander("ğŸ§  æ³•å¾‹æ¨ç†è¿‡ç¨‹").markdown(st.session_state["rag_res_r"])
                
                st.markdown("### âš–ï¸ æ³•å¾‹æ„è§")
                st.markdown(st.session_state["rag_res_a"])

                st.markdown("---")
                if st.button("ğŸ’¾ å½’æ¡£æ£€ç´¢è®°å½•"):
                    full_content = f"Q: {st.session_state['rag_query']}\n\nEvidence:\n{st.session_state['rag_context']}\n\nA:\n{st.session_state['rag_res_a']}"
                    save_to_db("RAG", f"æ£€ç´¢: {st.session_state['rag_query']}", full_content)

    # --- Tab 5: æ–°å“ ---
    with tabs[4]:
        st.subheader("ğŸ’¡ æ¦‚å¿µç”Ÿæˆ")
        st.caption("âš¡ å·²è‡ªåŠ¨é”å®šï¼šDeepSeek-V3 (æé€Ÿæ¨¡å¼) | åŸå› ï¼šV3 å…·æœ‰æ›´å¼ºçš„å‘æ•£æ€§æ€ç»´ï¼Œæ›´é€‚åˆåˆ›æ„è„‘æš´")
        col1, col2 = st.columns(2)
        with col1: base_product = st.text_input("åŸºåº•äº§å“", "0ç³–é…¸å¥¶")
        with col2: target_user = st.text_input("ç›®æ ‡äººç¾¤", "å‡è„‚æ‰“å·¥äºº")
        trend = st.selectbox("ç»“åˆè¶‹åŠ¿", ["è¯é£ŸåŒæº", "0ç³–0å¡", "é«˜è›‹ç™½", "åŠ©çœ /è§£å‹", "æ¸…æ´æ ‡ç­¾"])
        
        if st.button("ğŸ§ª ç”Ÿæˆæ¦‚å¿µä¹¦"):
            with st.spinner("ğŸ§  å¤´è„‘é£æš´ä¸­..."):
                prompt = f"ç”Ÿæˆé£Ÿå“æ–°å“æ¦‚å¿µä¹¦ï¼ŒMarkdownæ ¼å¼ã€‚åŸºåº•ï¼š{base_product}ï¼Œäººç¾¤ï¼š{target_user}ï¼Œè¶‹åŠ¿ï¼š{trend}"
                res = call_deepseek_once(prompt, "")
            st.session_state["idea_res"] = res
            st.session_state["idea_base"] = base_product
        
        if "idea_res" in st.session_state:
            st.markdown(st.session_state["idea_res"])
            st.plotly_chart(plot_radar(base_product, trend))
            if st.button("ğŸ’¾ äº‘ç«¯ä¿å­˜æ¦‚å¿µ"): 
                save_to_db("IDEA",f"æ¦‚å¿µ:{st.session_state['idea_base']}", st.session_state["idea_res"])

# --------------------------------------------------
#  MODE 2: è‡ªåª’ä½“å·¥å‚
# --------------------------------------------------
elif app_mode == "ğŸ¬ è‡ªåª’ä½“å·¥å‚":
    st.title("ğŸ¬ è‡ªåŠ¨åŒ–å†…å®¹å·¥å‚")
    st.caption("âš¡ å·²è‡ªåŠ¨é”å®šï¼šDeepSeek-V3 (æé€Ÿæ¨¡å¼) | åŸå› ï¼šç”Ÿæˆè„šæœ¬éœ€è¦é«˜ç½‘æ„Ÿå’Œé€Ÿåº¦")
    t1, t2 = st.tabs(["ğŸ“ è„šæœ¬", "ğŸ™ï¸ é…éŸ³"])
    with t1:
        c1,c2=st.columns([1,2])
        with c1:
            if st.button("ğŸ”„ åˆ·æ–°çƒ­æœ"): st.cache_data.clear()
            try:
                hot = requests.get("https://top.baidu.com/board?tab=realtime", headers={"UA":"Mozilla/5.0"}).text
                ts = [t.strip() for t in re.findall(r'ellipsis">(.*?)</div>', hot) if len(t)>4][:10]
                sel = st.radio("é€‰å–çƒ­ç‚¹", ts, index=None)
            except: sel=None
        with c2:
            top = st.text_input("é€‰é¢˜", sel if sel else "")
            c_type, c_style = st.columns(2)
            with c_type: script_type = st.selectbox("ç±»å‹", ["è¾Ÿè°£ç²‰ç¢æœº", "çº¢é»‘æ¦œæµ‹è¯„", "è¡Œä¸šå†…å¹•æ­ç§˜", "çƒ­ç‚¹åƒç“œè§£è¯»"])
            with c_style: visual_style = st.selectbox("é£æ ¼", ["å®æ‹ç”Ÿæ´»é£", "å®«å´éªåŠ¨æ¼«", "èµ›åšæœ‹å…‹é£", "å¾®è·ç¾é£Ÿ"])
            
            if st.button("ğŸš€ ç”Ÿæˆè„šæœ¬"):
                with st.spinner("æ­£åœ¨æ„å»ºåˆ†é•œè¡¨..."):
                    p = f"æˆ‘æ˜¯é£Ÿå“ç§‘æ™®åšä¸»ã€‚é€‰é¢˜ï¼š{top}ã€‚ç±»å‹ï¼š{script_type}ã€‚é£æ ¼ï¼š{visual_style}ã€‚è¯·è¾“å‡ºMarkdownåˆ†é•œè¡¨æ ¼ã€‚"
                    s = call_deepseek_once(p, "")
                st.session_state["scr"] = s
                st.rerun()
                
            if "scr" in st.session_state:
                st.markdown(st.session_state["scr"])
                if st.button("ğŸ’¾ äº‘ç«¯å­˜è„šæœ¬"): save_to_db("SCRIPT",top,st.session_state["scr"])

    with t2:
        st.subheader("ğŸ™ï¸ TTS é…éŸ³å®¤")
        txt = st.text_area("ç²˜è´´æ–‡æ¡ˆ")
        v = st.selectbox("éŸ³è‰²", ["zh-CN-YunxiNeural (ç”·å£°-ç¨³é‡)", "zh-CN-XiaoxiaoNeural (å¥³å£°-äº²åˆ‡)", "zh-CN-YunjianNeural (ç”·å£°-æ–°é—»)"])
        if st.button("ğŸ§ ç”Ÿæˆè¯­éŸ³"):
            with st.spinner("AI æ­£åœ¨åˆæˆéŸ³é¢‘æµ..."):
                try: 
                    st.audio(asyncio.run(generate_speech(txt,v.split(" ")[0])))
                    st.success("åˆæˆå®Œæ¯•")
                except: st.error("Error")

# --------------------------------------------------
#  MODE 3: äº‘ç«¯æ¡£æ¡ˆåº“
# --------------------------------------------------
elif app_mode == "ğŸ—„ï¸ äº‘ç«¯æ¡£æ¡ˆåº“":
    st.title("ğŸ—„ï¸ ç ”å‘ä¸åˆ›ä½œæ¡£æ¡ˆ (Cloud)")
    filter_type = st.radio("ç­›é€‰", ["å…¨éƒ¨","ELN","FORMULA","SCRIPT","IDEA","RAG"], horizontal=True)
    t = None if filter_type=="å…¨éƒ¨" else filter_type
    with st.spinner("æ­£åœ¨ä» Supabase åŒæ­¥æ•°æ®..."):
        recs = get_history(t)
    if not recs:
        st.info("â˜ï¸ äº‘ç«¯æ•°æ®åº“æš‚æ— æ•°æ®ã€‚")
    else:
        for r in recs:
            with st.expander(f"{r['timestamp']} | [{r['type']}] {r['title']}"):
                st.markdown(r['content'])
                st.download_button("å¯¼å‡ºMD", r['content'], f"{r['type']}_{r['id']}.md")

# --------------------------------------------------
#  MODE 4: äº‘ç«¯ç›‘æ§
# --------------------------------------------------
elif app_mode == "âš™ï¸ äº‘ç«¯ç›‘æ§":
    st.title("âš™ï¸ ç›‘æ§")
    if st.button("æµ‹è¯•æ¨é€") and "BARK_SERVER" in st.secrets:
        requests.get(f"{st.secrets['BARK_SERVER']}/{st.secrets['BARK_DEVICE_KEY']}/æµ‹è¯•")
        st.success("Sent")