import streamlit as st
import requests
import re
import pdfplumber
import pandas as pd
import plotly.graph_objects as go
import edge_tts
import asyncio
import json
import easyocr # æ–°å¢ï¼šOCR åº“
import numpy as np
from datetime import datetime
from io import BytesIO
from PIL import Image # ç”¨äºå¤„ç†ä¸Šä¼ çš„å›¾ç‰‡

# --- 1. é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(
    page_title="FoodMaster æ™ºèƒ½å·¥ä½œå°",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. ğŸ” ç™»å½•éªŒè¯ ---
def check_password():
    if st.session_state.get("password_correct", False):
        return True
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.title("ğŸ”’ FoodMaster Pro ç™»å½•")
        st.markdown("---")
        password = st.text_input("è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password")
        if st.button("ğŸš€ ç™»å½•ç³»ç»Ÿ"):
            correct_password = st.secrets.get("APP_PASSWORD", "123456")
            if password == correct_password:
                st.session_state["password_correct"] = True
                st.rerun()
            else:
                st.error("âŒ å¯†ç é”™è¯¯")
    return False

if not check_password():
    st.stop()

# ==================================================
#  é…ç½®ä¸å·¥å…·å‡½æ•°
# ==================================================

if "DEEPSEEK_API_KEY" not in st.secrets:
    st.error("âš ï¸ é…ç½®ç¼ºå¤±ï¼šè¯·åœ¨ Secrets ä¸­æ·»åŠ  DEEPSEEK_API_KEY")
    st.stop()
API_KEY = st.secrets["DEEPSEEK_API_KEY"]

# --- AI è°ƒç”¨ (æ”¯æŒ R1) ---
def call_deepseek_advanced(messages, model_type="chat"):
    url = "https://api.deepseek.com/chat/completions"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
    model_name = "deepseek-reasoner" if model_type == "reasoner" else "deepseek-chat"
    
    try:
        response = requests.post(url, headers=headers, json={
            "model": model_name,
            "messages": messages,
            "stream": False
        })
        if response.status_code == 200:
            res_json = response.json()
            message = res_json['choices'][0]['message']
            content = message.get('content', '')
            reasoning = message.get('reasoning_content', '')
            return reasoning, content
        else:
            return None, f"Error: {response.status_code} - {response.text}"
    except Exception as e:
        return None, f"è¯·æ±‚å¼‚å¸¸: {e}"

def call_deepseek_once(system_prompt, user_input):
    _, content = call_deepseek_advanced([
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_input}
    ], model_type="chat")
    return content

# --- TTS ---
async def generate_speech(text, voice):
    communicate = edge_tts.Communicate(text, voice)
    mp3_fp = BytesIO()
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            mp3_fp.write(chunk["data"])
    mp3_fp.seek(0)
    return mp3_fp

# --- OCR æ ¸å¿ƒå‡½æ•° (æ–°!) ---
@st.cache_resource # ä½¿ç”¨ç¼“å­˜ï¼Œé¿å…æ¯æ¬¡åˆ·æ–°éƒ½é‡æ–°åŠ è½½æ¨¡å‹ï¼Œè¿™å¾ˆå…³é”®ï¼
def load_ocr_reader():
    # åŠ è½½ç®€å†™ä¸­æ–‡(ch_sim)å’Œè‹±æ–‡(en)
    return easyocr.Reader(['ch_sim', 'en'], gpu=False) # äº‘ç«¯é€šå¸¸åªæœ‰CPU

def ocr_image(uploaded_file):
    """è¯»å–å›¾ç‰‡å¹¶æå–æ–‡å­—"""
    try:
        reader = load_ocr_reader()
        image = Image.open(uploaded_file)
        # EasyOCR éœ€è¦ numpy æ•°ç»„æ ¼å¼
        image_np = np.array(image)
        result = reader.readtext(image_np, detail=0) # detail=0 åªè¿”å›æ–‡å­—åˆ—è¡¨
        return " ".join(result)
    except Exception as e:
        return f"OCR è¯†åˆ«å¤±è´¥: {e}"

# --- ELN æŠ¥å‘Šç”Ÿæˆå™¨ ---
def generate_eln_report(messages, project_name="æœªå‘½åé¡¹ç›®"):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    report = f"# ğŸ§¬ FoodMaster ELN å®éªŒè®°å½•\n**é¡¹ç›®**: {project_name}\n**æ—¶é—´**: {timestamp}\n---\n\n"
    for msg in messages:
        if msg["role"] == "user": report += f"## ğŸ™‹â€â™‚ï¸ æé—®\n{msg['content']}\n\n"
        elif msg["role"] == "assistant": report += f"## ğŸ¤– å›ç­”\n{msg['content']}\n\n---\n"
    return report

# --- å…¶ä»–è¾…åŠ© ---
@st.cache_data(ttl=3600)
def get_realtime_news():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        url = "https://top.baidu.com/board?tab=realtime"
        resp = requests.get(url, headers=headers)
        titles = re.findall(r'class="c-single-text-ellipsis">(.*?)</div>', resp.text)
        return [t.strip() for t in titles if len(t) > 4][:10]
    except: return ["æš‚æ— çƒ­ç‚¹"]

def extract_text_from_pdf(file):
    try:
        with pdfplumber.open(file) as pdf:
            text = ""
            for page in pdf.pages[:5]: text += page.extract_text() + "\n"
            return text
    except: return ""

def plot_sensory_radar(product_name, trend):
    categories = ['ç”œåº¦', 'é…¸åº¦', 'è‹¦åº¦', 'å’¸åº¦', 'é²œåº¦']
    values = [3, 2, 1, 1, 2]
    if "é…¸å¥¶" in product_name: values = [3, 4, 1, 0, 2]
    if "0ç³–" in trend: values[0] = 1
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(r=values, theta=categories, fill='toself', name=product_name, line_color='#FF4B4B'))
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 5])), showlegend=False, margin=dict(t=20, b=20, l=40, r=40))
    return fig

# --- ä¾§è¾¹æ  ---
st.sidebar.title("ğŸ§¬ FoodMaster Pro")
st.sidebar.caption("é£Ÿå“ç¡•å£«çš„æ•°å­—åŒ–è§£å†³æ–¹æ¡ˆ")

app_mode = st.sidebar.selectbox(
    "é€‰æ‹©å·¥ä½œæ¨¡å¼",
    ["ğŸ”¬ R&D ç ”å‘ä¸åˆè§„ (Visualç‰ˆ)", "ğŸ¬ è‡ªåª’ä½“å†…å®¹çŸ©é˜µ", "âš™ï¸ äº‘ç«¯æ•°æ®çœ‹æ¿"]
)

# ==================================================
# æ¨¡å— 1: R&D ç ”å‘ (é›†æˆ Vision)
# ==================================================
if app_mode == "ğŸ”¬ R&D ç ”å‘ä¸åˆè§„ (Visualç‰ˆ)":
    st.title("ğŸ”¬ æ™ºèƒ½ç ”å‘ä¸æ³•è§„åŠ©æ‰‹")
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ§  å¤§è„‘é…ç½®")
    model_choice = st.sidebar.radio("é€‰æ‹©æ¨¡å‹", ["ğŸš€ V3 æé€Ÿç‰ˆ", "ğŸ§  R1 æ·±åº¦æ€è€ƒ"], index=0)
    current_model = "reasoner" if "R1" in model_choice else "chat"

    if "messages_law" not in st.session_state:
        st.session_state["messages_law"] = [{"role": "system", "content": "ä½ æ˜¯ä¸€åèµ„æ·±çš„é£Ÿå“æ³•è§„ä¸“å‘˜ã€‚"}]
    
    # ELN å¯¼å‡º
    st.sidebar.markdown("---")
    if len(st.session_state["messages_law"]) > 1:
        report = generate_eln_report(st.session_state["messages_law"])
        st.sidebar.download_button("ğŸ“¥ å¯¼å‡ºå®éªŒæŠ¥å‘Š", report, file_name="ELN.md")

    # æ–°å¢ Tab 4: è§†è§‰é…æ–™åˆ†æ
    tab1, tab2, tab4, tab3 = st.tabs(["ğŸ’¬ æ³•è§„å¯¹è¯", "ğŸ“„ æ–‡æ¡£Chat", "ğŸ“¸ è§†è§‰é…æ–™åˆ†æ (OCR)", "ğŸ“Š æ–°å“ç ”å‘"])

    # --- Tab 1: æ³•è§„å¯¹è¯ ---
    with tab1:
        for msg in st.session_state["messages_law"]:
            if msg["role"] != "system":
                with st.chat_message(msg["role"]):
                    if "reasoning" in msg:
                        with st.expander("ğŸ§  æ€ç»´é“¾"): st.markdown(msg["reasoning"])
                    st.markdown(msg["content"])
        
        if prompt := st.chat_input("è¾“å…¥é—®é¢˜..."):
            st.session_state["messages_law"].append({"role": "user", "content": prompt})
            with st.chat_message("user"): st.markdown(prompt)
            with st.chat_message("assistant"):
                with st.spinner("AI æ€è€ƒä¸­..."):
                    r, a = call_deepseek_advanced(st.session_state["messages_law"], current_model)
                if r: 
                    with st.expander("ğŸ§  æ€ç»´é“¾"): st.markdown(r)
                st.markdown(a)
                st.session_state["messages_law"].append({"role": "assistant", "content": a, "reasoning": r})
            
    # --- Tab 4: è§†è§‰é…æ–™åˆ†æ (æ ¸å¿ƒæ–°åŠŸèƒ½) ---
    with tab4:
        st.subheader("ğŸ“¸ è§†è§‰é…æ–™è¡¨åˆ†æ (AI Vision)")
        st.info("åœºæ™¯ï¼šä¸Šä¼ é£Ÿå“åŒ…è£…/é…æ–™è¡¨ç…§ç‰‡ï¼ŒAI è‡ªåŠ¨æå–æ–‡å­—å¹¶åˆ†ææ½œåœ¨é£é™©ã€‚")
        
        img_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡ (JPG/PNG)", type=["jpg", "png", "jpeg"])
        
        if img_file:
            # æ˜¾ç¤ºå›¾ç‰‡
            st.image(img_file, caption="ä¸Šä¼ çš„å›¾ç‰‡", width=300)
            
            if st.button("ğŸ‘ï¸ å¼€å§‹è¯†åˆ«å¹¶åˆ†æ"):
                with st.spinner("ğŸ” æ­£åœ¨è¿›è¡Œ OCR æ–‡å­—æå– (é¦–æ¬¡è¿è¡Œå¯èƒ½è¾ƒæ…¢)..."):
                    # 1. æå–æ–‡å­—
                    extracted_text = ocr_image(img_file)
                
                if extracted_text and "å¤±è´¥" not in extracted_text:
                    st.success("âœ… æ–‡å­—æå–æˆåŠŸï¼")
                    with st.expander("æŸ¥çœ‹æå–åˆ°çš„åŸå§‹æ–‡å­—"):
                        st.code(extracted_text)
                    
                    # 2. äº¤ç»™ AI åˆ†æ
                    with st.spinner("ğŸ§  R1 æ­£åœ¨æ·±åº¦åˆ†æé…æ–™è¡¨..."):
                        sys_prompt = """
                        ä½ æ˜¯ä¸€åé£Ÿå“å®‰å…¨ä¸“å®¶ã€‚ç”¨æˆ·ä¼šæä¾›ä¸€æ®µä»é£Ÿå“åŒ…è£…ä¸Šè¯†åˆ«å‡ºçš„æ–‡å­—ï¼ˆå¯èƒ½åŒ…å«ä¹±ç ï¼‰ã€‚
                        è¯·åšä»¥ä¸‹åˆ†æï¼š
                        1. ã€æ•´ç†ã€‘ï¼šä¿®æ­£OCRè¯†åˆ«é”™è¯¯çš„é£Ÿå“æ·»åŠ å‰‚åç§°ã€‚
                        2. ã€é£é™©ã€‘ï¼šæŒ‡å‡ºæ˜¯å¦å«æœ‰è‡´æ•åŸã€åå¼è„‚è‚ªé…¸æˆ–å—äº‰è®®çš„æ·»åŠ å‰‚ã€‚
                        3. ã€è¯„ä»·ã€‘ï¼šåŸºäºé…æ–™è¡¨åˆ¤æ–­è¯¥äº§å“çš„åŠ å·¥åŠ å·¥ç¨‹åº¦ï¼ˆæ¸…æ´æ ‡ç­¾ç¨‹åº¦ï¼‰ã€‚
                        """
                        # è¿™é‡Œå¼ºåˆ¶ä½¿ç”¨ R1 è¿›è¡Œæ·±åº¦æ¨ç†ï¼Œå› ä¸ºåˆ†æé…æ–™è¡¨éœ€è¦é€»è¾‘
                        r, a = call_deepseek_advanced([
                            {"role": "system", "content": sys_prompt},
                            {"role": "user", "content": f"è¯†åˆ«åˆ°çš„é…æ–™è¡¨å†…å®¹ï¼š{extracted_text}"}
                        ], model_type="reasoner")
                        
                        if r:
                            with st.expander("ğŸ§  AI åˆ†æé€»è¾‘"): st.markdown(r)
                        st.markdown("### ğŸ¥— é…æ–™è¡¨æ·±åº¦åˆ†ææŠ¥å‘Š")
                        st.markdown(a)
                        
                        # è‡ªåŠ¨å­˜å…¥å¯¹è¯å†å²ï¼Œæ–¹ä¾¿å¯¼å‡º ELN
                        st.session_state["messages_law"].append({
                            "role": "user", 
                            "content": f"[å›¾ç‰‡åˆ†æ] é…æ–™è¡¨å†…å®¹ï¼š{extracted_text}"
                        })
                        st.session_state["messages_law"].append({
                            "role": "assistant", 
                            "content": a,
                            "reasoning": r
                        })
                else:
                    st.error(extracted_text)

    # --- Tab 2: æ–‡æ¡£å¯¹è¯ ---
    with tab2:
        st.subheader("ğŸ“„ æ–‡æ¡£å¯¹è¯")
        uploaded_files = st.file_uploader("ä¸Šä¼ PDF", type="pdf", accept_multiple_files=True)
        if uploaded_files and st.button("è¯»å–"):
            c = ""
            for f in uploaded_files: c += f"\n--- {f.name} ---\n{extract_text_from_pdf(f)}\n"
            st.session_state["pdf_context"] = c
            st.session_state["messages_doc"] = [{"role":"system","content":f"å†…å®¹:\n{c[:8000]}"}]
            st.success("è¯»å–å®Œæˆ")
        
        if "messages_doc" in st.session_state:
            for m in st.session_state["messages_doc"]:
                if m["role"]!="system":
                    with st.chat_message(m["role"]): st.markdown(m["content"])
            if p:=st.chat_input("é—®æ–‡æ¡£", key="doc_chat"):
                st.session_state["messages_doc"].append({"role":"user","content":p})
                with st.chat_message("user"): st.markdown(p)
                r, a = call_deepseek_advanced(st.session_state["messages_doc"], current_model)
                with st.chat_message("assistant"): st.markdown(a)
                st.session_state["messages_doc"].append({"role":"assistant","content":a})

    # --- Tab 3: æ–°å“ç ”å‘ ---
    with tab3:
        st.subheader("ğŸ’¡ æ–°å“æ¦‚å¿µ")
        c1,c2=st.columns(2)
        with c1: base=st.text_input("åŸºåº•","0ç³–é…¸å¥¶")
        with c2: user=st.text_input("äººç¾¤","å‡è„‚å…š")
        trend=st.selectbox("è¶‹åŠ¿",["è¯é£ŸåŒæº","0ç³–"])
        if st.button("ç”Ÿæˆ"):
            col_t, col_c = st.columns([3, 2])
            with col_t: st.markdown(call_deepseek_once("ç”Ÿæˆæ¦‚å¿µä¹¦", f"{base} {user} {trend}"))
            with col_c: st.plotly_chart(plot_sensory_radar(base, trend))

# ==================================================
# æ¨¡å— 2: è‡ªåª’ä½“
# ==================================================
elif app_mode == "ğŸ¬ è‡ªåª’ä½“å†…å®¹çŸ©é˜µ":
    st.title("ğŸ¬ è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿäº§å·¥å‚")
    tab_script, tab_voice = st.tabs(["ğŸ“ è„šæœ¬ç”Ÿæˆ", "ğŸ™ï¸ AIé…éŸ³"])
    with tab_script:
        col_h, col_g = st.columns([1,2])
        with col_h:
            if st.button("åˆ·æ–°"): st.cache_data.clear()
            hot=get_realtime_news()
            sel=st.radio("çƒ­ç‚¹",hot,index=None)
            if sel: st.session_state['sel']=sel
        with col_g:
            top=st.text_input("é€‰é¢˜",st.session_state.get('sel',''))
            if st.button("ç”Ÿæˆè„šæœ¬"):
                st.markdown(call_deepseek_once(f"å†™è„šæœ¬ï¼Œé€‰é¢˜ï¼š{top}",""))
    with tab_voice:
        txt=st.text_area("æ–‡æ¡ˆ")
        if st.button("ç”Ÿæˆè¯­éŸ³"):
            try:
                mp3=asyncio.run(generate_speech(txt,"zh-CN-YunxiNeural"))
                st.audio(mp3)
            except: st.error("å¤±è´¥")

# ==================================================
# æ¨¡å— 3: äº‘ç«¯çœ‹æ¿
# ==================================================
elif app_mode == "âš™ï¸ äº‘ç«¯æ•°æ®çœ‹æ¿":
    st.title("âš™ï¸ è‡ªåŠ¨åŒ–ç³»ç»Ÿç›‘æ§")
    st.info("daily_task.py æ¯æ—¥ 08:00 è¿è¡Œ")
    if st.button("æµ‹è¯•æ¨é€"):
        if "BARK_SERVER" in st.secrets:
            requests.get(f"{st.secrets['BARK_SERVER']}/{st.secrets['BARK_DEVICE_KEY']}/æµ‹è¯•")
            st.success("å·²å‘é€")