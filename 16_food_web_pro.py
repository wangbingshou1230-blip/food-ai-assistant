import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import json
import PyPDF2
import matplotlib.pyplot as plt
import os

# 1. åŸºç¡€é…ç½®
st.set_page_config(page_title="FoodAI ç§‘ç ”ä¸­å° Pro", page_icon="ğŸ§¬", layout="wide")

# ================= ğŸ” å®‰å…¨ç™»å½•æ¨¡å— =================
def check_password():
    """æ£€æŸ¥å¯†ç æ˜¯å¦æ­£ç¡®"""
    if "password_correct" not in st.session_state:
        st.session_state.password_correct = False

    if st.session_state.password_correct:
        return True # å·²ç™»å½•

    # æ˜¾ç¤ºè¾“å…¥æ¡†
    st.markdown("### ğŸ”’ è¯·è¾“å…¥è®¿é—®å¯†ç ")
    pwd = st.text_input("Password", type="password")
    
    # éªŒè¯é€»è¾‘ (è¿™é‡Œæˆ‘ä»¬æŠŠå¯†ç è®¾ä¸º 123456ï¼Œä½ ä¹Ÿå¯ä»¥å» secrets é‡Œæ”¹)
    if st.button("ç™»å½•"):
        if pwd == st.secrets.get("app_password", "123456"): # ä¼˜å…ˆè¯»å–äº‘ç«¯é…ç½®çš„å¯†ç 
            st.session_state.password_correct = True
            st.rerun() # åˆ·æ–°é¡µé¢è¿›å…¥ç³»ç»Ÿ
        else:
            st.error("âŒ å¯†ç é”™è¯¯")
    return False

# å¦‚æœæ²¡ç™»å½•ï¼Œå°±åœæ­¢è¿è¡Œä¸‹é¢çš„ä»£ç 
if not check_password():
    st.stop()
# ================================================

# ... (ä»¥ä¸‹æ˜¯åŸæ¥çš„æ‰€æœ‰åŠŸèƒ½ä»£ç ï¼Œä¿æŒä¸å˜) ...

# åŠ è½½é…ç½®
def load_config():
    if os.path.exists("config.json"):
        with open("config.json", "r", encoding="utf-8") as f:
            return json.load(f)
    elif hasattr(st, "secrets"):
        return st.secrets
    return {}

CONFIG = load_config()
API_KEY = CONFIG.get("deepseek_api_key", "")
PROXY_URL = CONFIG.get("proxy_url", "")

# ä¾§è¾¹æ 
with st.sidebar:
    st.title("ğŸ›ï¸ æ§åˆ¶å°")
    st.success(f"âœ… å·²å®‰å…¨ç™»å½•") # ç™»å½•æˆåŠŸæç¤º
    page = st.radio("åŠŸèƒ½å¯¼èˆª", ["ğŸ“¢ è¡Œä¸šæƒ…æŠ¥ç›‘æµ‹", "ğŸ“„ æ–‡çŒ®æ™ºèƒ½é˜…è¯»", "ğŸ“ˆ å®éªŒæ•°æ®åˆ†æ"])

# --- åé¢æ‰€æœ‰çš„å‡½æ•°å’Œé¡µé¢é€»è¾‘(search_bing, ask_deepseekç­‰)å…¨éƒ¨ç…§æ¬åŸæ¥çš„ ---
# (è¯·æŠŠä¹‹å‰ä»£ç é‡Œ check_password ä¹‹åçš„éƒ¨åˆ†å…¨éƒ¨ç²˜è´´åœ¨è¿™é‡Œ)
# ...
def search_bing(q):
    """çœŸÂ·çˆ¬è™«æ¨¡å—"""
    headers = { "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36" }
    try:
        r = requests.get(f"https://cn.bing.com/search?q={q}", headers=headers, timeout=15)
        soup = BeautifulSoup(r.text, 'html.parser')
        results = []
        for item in soup.select('li.b_algo h2 a'):
            results.append(f"- {item.get_text()} ({item.get('href')})")
        return "\n".join(results[:8]) if results else "æœªæ‰¾åˆ°æœ‰æ•ˆæœç´¢ç»“æœ"
    except Exception as e: return f"æœç´¢å‡ºé”™: {e}"

def ask_deepseek(system_prompt, user_content):
    """çœŸÂ·AIæ¨¡å—"""
    if not API_KEY: return "âŒ è¯·å…ˆé…ç½® API Key"
    try:
        headers = {"Authorization": f"Bearer {API_KEY}"}
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ]
        }
        # å¦‚æœæœ‰é…ç½®ä»£ç†ï¼Œä½¿ç”¨ä»£ç†
        proxies = {"http": PROXY_URL, "https": PROXY_URL} if PROXY_URL else None
        
        resp = requests.post("https://api.deepseek.com/chat/completions", headers=headers, json=payload, proxies=proxies, timeout=12030)
        return resp.json()['choices'][0]['message']['content']
    except Exception as e: return f"AI è°ƒç”¨å‡ºé”™: {e}"

def extract_pdf_text(uploaded_file):
    """PDF è§£ææ¨¡å—"""
    try:
        reader = PyPDF2.PdfReader(uploaded_file)
        return "".join([p.extract_text() for p in reader.pages])
    except: return ""

# ================= 2. é¡µé¢é€»è¾‘ =================

# --- æ¨¡å— A: æƒ…æŠ¥ç›‘æµ‹ ---
if page == "ğŸ“¢ è¡Œä¸šæƒ…æŠ¥ç›‘æµ‹":
    st.title("ğŸ“¢ è¡Œä¸šæƒ…æŠ¥ç›‘æµ‹ä¸­å¿ƒ")
    st.markdown("---")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        keyword = st.text_input("è¯·è¾“å…¥ç›‘æµ‹å…³é”®è¯", "éçƒ­æ€èŒæŠ€æœ¯")
    with col2:
        st.write("") # å ä½
        st.write("") 
        start_btn = st.button("ğŸš€ å¼€å§‹å…¨ç½‘æ‰«æ", type="primary", use_container_width=True)

    if start_btn:
        with st.status("æ­£åœ¨æ‰§è¡Œè‡ªåŠ¨åŒ–ä»»åŠ¡...", expanded=True) as status:
            st.write("ğŸ•µï¸ æ­£åœ¨æ½œå…¥ Bing æœç´¢æœ€æ–°æƒ…æŠ¥...")
            search_data = search_bing(keyword)
            st.code(search_data[:200] + "...", language="text") # å±•ç¤ºä¸€éƒ¨åˆ†æŠ“å–ç»“æœ
            
            st.write("ğŸ§  æ­£åœ¨å”¤é†’ DeepSeek å¤§è„‘è¿›è¡Œåˆ†æ...")
            report = ask_deepseek("ä½ æ˜¯ä¸€ä½é£Ÿå“è¡Œä¸šæƒ…æŠ¥åˆ†æä¸“å®¶ï¼Œè¯·æ ¹æ®æœç´¢ç»“æœæ’°å†™ç®€æŠ¥ã€‚", f"å…³é”®è¯ï¼š{keyword}\næœç´¢ç»“æœï¼š\n{search_data}")
            
            status.update(label="âœ… åˆ†æå®Œæˆï¼", state="complete", expanded=False)
        
        st.subheader("ğŸ“ AI åˆ†ææŠ¥å‘Š")
        st.markdown(report)
        st.download_button("ğŸ’¾ ä¸‹è½½æŠ¥å‘Š", report, file_name=f"{keyword}_report.md")

# --- æ¨¡å— B: æ–‡çŒ®é˜…è¯» ---
elif page == "ğŸ“„ æ–‡çŒ®æ™ºèƒ½é˜…è¯»":
    st.title("ğŸ“„ æ–‡çŒ®æ™ºèƒ½é˜…è¯»åŠ©æ‰‹")
    st.markdown("---")
    
    uploaded_pdf = st.file_uploader("æ‹–å…¥ PDF æ–‡çŒ® (æ”¯æŒç‚¹å‡»ä¸Šä¼ )", type="pdf")
    
    if uploaded_pdf:
        with st.spinner("æ­£åœ¨æå–æ–‡æœ¬..."):
            text = extract_pdf_text(uploaded_pdf)
            st.success(f"å·²åŠ è½½: {uploaded_pdf.name} (å…± {len(text)} å­—)")
        
        question = st.text_input("ğŸ’¡ é’ˆå¯¹è¿™ç¯‡è®ºæ–‡ï¼Œä½ æƒ³é—®ä»€ä¹ˆï¼Ÿ", "è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ")
        
        if st.button("ğŸ§  æ·±åº¦é˜…è¯»"):
            with st.spinner("AI æ­£åœ¨é˜…è¯»è®ºæ–‡..."):
                answer = ask_deepseek("ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„ç§‘ç ”åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä¸‹æ–‡å›ç­”é—®é¢˜ã€‚", f"é—®é¢˜ï¼š{question}\nåŸæ–‡ç‰‡æ®µï¼š\n{text[:20000]}")
                st.markdown("### ğŸ“ å›ç­”ï¼š")
                st.markdown(answer)

# --- æ¨¡å— C: æ•°æ®åˆ†æ ---
elif page == "ğŸ“ˆ å®éªŒæ•°æ®åˆ†æ":
    st.title("ğŸ“ˆ å®éªŒæ•°æ®è‡ªåŠ¨åŒ–åˆ†æ")
    st.info("æ”¯æŒæ‰¹é‡ä¸Šä¼ å¤šä¸ª Excel (.xlsx) æ–‡ä»¶ï¼Œè‡ªåŠ¨åˆå¹¶å¹¶è®¡ç®— Mean Â± SD")
    st.markdown("---")
    
    # æ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader("è¯·é€‰æ‹©å®éªŒæ•°æ®æ–‡ä»¶ (å¯å¤šé€‰)", type="xlsx", accept_multiple_files=True)
    
    if uploaded_files:
        if st.button("âš¡ å¼€å§‹æ‰¹é‡å¤„ç†"):
            all_data = []
            for f in uploaded_files:
                df = pd.read_excel(f)
                all_data.append(df)
            
            # åˆå¹¶æ•°æ®
            big_df = pd.concat(all_data, ignore_index=True)
            
            # è®¡ç®—ç»Ÿè®¡é‡
            summary = big_df.groupby("æ—¶é—´ (h)")["pHå€¼"].agg(["mean", "std"])
            
            # å±•ç¤ºä¸¤åˆ—ï¼šå·¦è¾¹è¡¨æ ¼ï¼Œå³è¾¹å›¾è¡¨
            c1, c2 = st.columns([1, 2])
            
            with c1:
                st.subheader("ğŸ“‹ ç»Ÿè®¡æ•°æ®")
                st.dataframe(summary)
            
            with c2:
                st.subheader("ğŸ“Š ç§‘ç ”ç»˜å›¾ (å¸¦è¯¯å·®å¸¦)")
                # ç”¨ Matplotlib ç”»å›¾ (ä¸ºäº†é‚£ä¸ªæ¼‚äº®çš„è¯¯å·®å¸¦)
                fig, ax = plt.subplots(figsize=(8, 5))
                plt.rcParams['font.sans-serif'] = ['SimHei'] # è§£å†³ä¸­æ–‡ä¹±ç 
                plt.rcParams['axes.unicode_minus'] = False
                
                ax.plot(summary.index, summary["mean"], color="#FF4B4B", label="pH å¹³å‡å€¼", linewidth=2)
                ax.fill_between(summary.index, 
                                summary["mean"] - summary["std"], 
                                summary["mean"] + summary["std"], 
                                color="#FF4B4B", alpha=0.2, label="è¯¯å·®èŒƒå›´ (Â±SD)")
                ax.set_xlabel("æ—¶é—´ (h)")
                ax.set_ylabel("pH å€¼")
                ax.legend()
                ax.grid(True, linestyle='--', alpha=0.5)
                
                # ğŸ”¥ å…³é”®ï¼šæŠŠ Matplotlib å›¾è¡¨æ˜¾ç¤ºåœ¨ç½‘é¡µä¸Š
                st.pyplot(fig)