import streamlit as st
import requests
import re
import pdfplumber
import pandas as pd
import plotly.graph_objects as go
import edge_tts
import asyncio
from io import BytesIO

# --- 1. é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(
    page_title="FoodMaster æ™ºèƒ½å·¥ä½œå°",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. ğŸ” ç™»å½•éªŒè¯ ---
def check_password():
    if st.session_state.get("password_correct", False):
        return True
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.title("ğŸ”’ FoodMaster Pro ç™»å½•")
        st.markdown("---")
        password = st.text_input("è¯·è¾“å…¥è®¿é—®å¯†ç ", type="password")
        if st.button("ğŸš€ ç™»å½•ç³»ç»Ÿ"):
            correct_password = st.secrets.get("APP_PASSWORD", "123456")
            if password == correct_password:
                st.session_state["password_correct"] = True
                st.rerun()
            else:
                st.error("âŒ å¯†ç é”™è¯¯")
    return False

if not check_password():
    st.stop()

# ==================================================
#  é…ç½®ä¸æ ¸å¿ƒå·¥å…·å‡½æ•°
# ==================================================

if "DEEPSEEK_API_KEY" not in st.secrets:
    st.error("âš ï¸ é…ç½®ç¼ºå¤±ï¼šè¯·åœ¨ Secrets ä¸­æ·»åŠ  DEEPSEEK_API_KEY")
    st.stop()
API_KEY = st.secrets["DEEPSEEK_API_KEY"]

# --- æ ¸å¿ƒ AI è°ƒç”¨ (æ”¯æŒ R1 æ€ç»´é“¾) ---
def call_deepseek_advanced(messages, model_type="chat"):
    """
    model_type: "chat" (V3æé€Ÿç‰ˆ) or "reasoner" (R1æ·±åº¦æ€è€ƒç‰ˆ)
    è¿”å›: (thinking_content, answer_content)
    """
    url = "https://api.deepseek.com/chat/completions"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {API_KEY}"}
    
    # æ˜ å°„æ¨¡å‹åç§°
    model_name = "deepseek-reasoner" if model_type == "reasoner" else "deepseek-chat"
    
    try:
        # Streamlit çš„ Spinner åªèƒ½åœ¨è¿™é‡Œæ˜¾ç¤ºç®€å•çš„åŠ è½½
        # å…·ä½“çš„æ€è€ƒè¿‡ç¨‹å±•ç¤ºåœ¨ UI å±‚å¤„ç†
        response = requests.post(url, headers=headers, json={
            "model": model_name,
            "messages": messages,
            "stream": False
        })
        
        if response.status_code == 200:
            res_json = response.json()
            message = res_json['choices'][0]['message']
            
            # æå–å†…å®¹
            content = message.get('content', '')
            # æå–æ€ç»´é“¾ (åªæœ‰ reasoner æ¨¡å¼æ‰æœ‰)
            reasoning = message.get('reasoning_content', '')
            
            return reasoning, content
        else:
            return None, f"Error: {response.status_code} - {response.text}"
            
    except Exception as e:
        return None, f"è¯·æ±‚å¼‚å¸¸: {e}"

# ç®€æ˜“è°ƒç”¨åŒ…è£… (éå¯¹è¯æ¨¡å¼ç”¨)
def call_deepseek_once(system_prompt, user_input):
    _, content = call_deepseek_advanced([
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_input}
    ], model_type="chat") # é»˜è®¤ç”¨V3
    return content

# --- è¯­éŸ³åˆæˆ ---
async def generate_speech(text, voice):
    communicate = edge_tts.Communicate(text, voice)
    mp3_fp = BytesIO()
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            mp3_fp.write(chunk["data"])
    mp3_fp.seek(0)
    return mp3_fp

# --- å…¶ä»–è¾…åŠ© ---
@st.cache_data(ttl=3600)
def get_realtime_news():
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        url = "https://top.baidu.com/board?tab=realtime"
        resp = requests.get(url, headers=headers)
        titles = re.findall(r'class="c-single-text-ellipsis">(.*?)</div>', resp.text)
        return [t.strip() for t in titles if len(t) > 4][:10]
    except Exception as e:
        return [f"æŠ“å–å¼‚å¸¸: {e}"]

def extract_text_from_pdf(file):
    try:
        with pdfplumber.open(file) as pdf:
            text = ""
            for page in pdf.pages[:5]: text += page.extract_text() + "\n"
            return text
    except: return ""

def plot_sensory_radar(product_name, trend):
    categories = ['ç”œåº¦', 'é…¸åº¦', 'è‹¦åº¦', 'å’¸åº¦', 'é²œåº¦']
    values = [3, 2, 1, 1, 2] # Default
    if "é…¸å¥¶" in product_name: values = [3, 4, 1, 0, 2]
    elif "å’–å•¡" in product_name: values = [2, 3, 5, 0, 1]
    elif "èŒ¶" in product_name: values = [1, 2, 4, 0, 3]
    if "0ç³–" in trend: values[0] = 1
    
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=values, theta=categories, fill='toself', name=product_name, line_color='#FF4B4B'
    ))
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 5])), showlegend=False, margin=dict(t=20, b=20, l=40, r=40))
    return fig

# --- ä¾§è¾¹æ  ---
st.sidebar.title("ğŸ§¬ FoodMaster Pro")
st.sidebar.caption("é£Ÿå“ç¡•å£«çš„æ•°å­—åŒ–è§£å†³æ–¹æ¡ˆ")

app_mode = st.sidebar.selectbox(
    "é€‰æ‹©å·¥ä½œæ¨¡å¼",
    ["ğŸ”¬ R&D ç ”å‘ä¸åˆè§„ (R1æ¨ç†ç‰ˆ)", "ğŸ¬ è‡ªåª’ä½“å†…å®¹çŸ©é˜µ", "âš™ï¸ äº‘ç«¯æ•°æ®çœ‹æ¿"]
)

# ==================================================
# æ¨¡å— 1: R&D ç ”å‘ (é›†æˆ R1 æ¨ç†æ¨¡å‹)
# ==================================================
if app_mode == "ğŸ”¬ R&D ç ”å‘ä¸åˆè§„ (R1æ¨ç†ç‰ˆ)":
    st.title("ğŸ”¬ æ™ºèƒ½ç ”å‘ä¸æ³•è§„åŠ©æ‰‹")
    
    # --- ä¾§è¾¹æ å¢åŠ æ¨¡å‹æ§åˆ¶ ---
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ§  å¤§è„‘é…ç½®")
    model_choice = st.sidebar.radio(
        "é€‰æ‹©æ€è€ƒæ¨¡å‹",
        ["ğŸš€ DeepSeek-V3 (æé€Ÿæ¨¡å¼)", "ğŸ§  DeepSeek-R1 (æ·±åº¦æ€è€ƒ)"],
        index=0,
        help="V3é€‚åˆå¿«é€Ÿé—®ç­”ï¼›R1é€‚åˆå¤æ‚é€»è¾‘æ¨ç†ï¼Œä¼šå±•ç¤ºæ€ç»´é“¾ã€‚"
    )
    # å°†é€‰é¡¹è½¬æ¢ä¸ºä»£ç æ ‡è¯†
    current_model = "reasoner" if "R1" in model_choice else "chat"

    # åˆå§‹åŒ–èŠå¤©è®°å½•
    if "messages_law" not in st.session_state:
        st.session_state["messages_law"] = [{"role": "system", "content": "ä½ æ˜¯ä¸€åèµ„æ·±çš„é£Ÿå“æ³•è§„ä¸“å‘˜ã€‚"}]
    
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ æ³•è§„æ™ºèƒ½å¯¹è¯", "ğŸ“„ æ™ºèƒ½æ–‡æ¡£ Chat", "ğŸ“Š æ–°å“ç ”å‘å¯è§†åŒ–"])

    # --- Tab 1: æ³•è§„å¯¹è¯ ---
    with tab1:
        # æ˜¾ç¤ºå†å²æ¶ˆæ¯
        for msg in st.session_state["messages_law"]:
            if msg["role"] != "system":
                with st.chat_message(msg["role"]):
                    # å¦‚æœå†å²æ¶ˆæ¯é‡Œæœ‰æ€è€ƒè¿‡ç¨‹ï¼Œä¹Ÿæ˜¾ç¤ºå‡ºæ¥ï¼ˆå¯é€‰ï¼Œè¿™é‡Œç®€åŒ–åªæ˜¾ç¤ºå†…å®¹ï¼‰
                    st.markdown(msg["content"])
        
        # è¾“å…¥æ¡†
        if prompt := st.chat_input("è¾“å…¥åˆè§„é—®é¢˜ (è¯•ç€é—®ä¸€äº›å¤æ‚çš„é€»è¾‘é¢˜)..."):
            # 1. æ˜¾ç¤ºç”¨æˆ·æé—®
            st.session_state["messages_law"].append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # 2. è°ƒç”¨ AI
            with st.chat_message("assistant"):
                status_text = "AI æ­£åœ¨æé€Ÿå“åº”..." if current_model == "chat" else "AI æ­£åœ¨æ·±åº¦æ¨ç† (Chain of Thought)..."
                with st.spinner(status_text):
                    reasoning, answer = call_deepseek_advanced(st.session_state["messages_law"], model_type=current_model)
                
                # 3. å¦‚æœæœ‰æ€è€ƒè¿‡ç¨‹ï¼Œä½¿ç”¨ Expander å±•ç¤º
                if reasoning:
                    with st.expander("ğŸ§  ç‚¹å‡»æŸ¥çœ‹ AI çš„æ·±åº¦æ€è€ƒè¿‡ç¨‹ (CoT)"):
                        st.markdown(reasoning)
                
                # 4. æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
                st.markdown(answer)
                
                # 5. ä¿å­˜åˆ°å†å²
                # æ³¨æ„ï¼šä¸ºäº†èŠ‚çœ Tokenï¼Œé€šå¸¸åªä¿å­˜æœ€ç»ˆç­”æ¡ˆè¿›å†å²ä¸Šä¸‹æ–‡
                st.session_state["messages_law"].append({"role": "assistant", "content": answer})

        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯"):
            st.session_state["messages_law"] = [{"role": "system", "content": "ä½ æ˜¯ä¸€åèµ„æ·±çš„é£Ÿå“æ³•è§„ä¸“å‘˜ã€‚"}]
            st.rerun()

    # --- Tab 2: æ–‡æ¡£å¯¹è¯ ---
    with tab2:
        st.subheader("ğŸ“„ æ™ºèƒ½æ–‡æ¡£å¯¹è¯ (æ”¯æŒ R1 æ¨ç†)")
        uploaded_files = st.file_uploader("ä¸Šä¼  PDF", type="pdf", accept_multiple_files=True)
        if "messages_doc" not in st.session_state: st.session_state["messages_doc"] = []
        if "pdf_context" not in st.session_state: st.session_state["pdf_context"] = ""

        if uploaded_files:
            if st.button("ğŸ“¥ è¯»å–æ–‡æ¡£"):
                content = ""
                for file in uploaded_files: content += f"\n--- {file.name} ---\n{extract_text_from_pdf(file)}\n"
                st.session_state["pdf_context"] = content
                st.success(f"å·²è¯»å– {len(uploaded_files)} ä¸ªæ–‡ä»¶")
                st.session_state["messages_doc"] = [{"role": "system", "content": f"åŸºäºä»¥ä¸‹å†…å®¹å›ç­”:\n{content[:8000]}"}]

        if st.session_state["pdf_context"]:
            for msg in st.session_state["messages_doc"]:
                if msg["role"] != "system":
                    with st.chat_message(msg["role"]): st.markdown(msg["content"])
            
            if prompt := st.chat_input("æé—®æ–‡æ¡£..."):
                st.session_state["messages_doc"].append({"role": "user", "content": prompt})
                with st.chat_message("user"): st.markdown(prompt)
                
                # è¿™é‡Œä¹Ÿå¤ç”¨å½“å‰çš„ model_choice
                with st.chat_message("assistant"):
                    with st.spinner("AI é˜…è¯»ä¸æ€è€ƒä¸­..."):
                        reasoning, answer = call_deepseek_advanced(st.session_state["messages_doc"], model_type=current_model)
                    if reasoning:
                        with st.expander("ğŸ§  æŸ¥çœ‹æ–‡æ¡£åˆ†æé€»è¾‘"):
                            st.markdown(reasoning)
                    st.markdown(answer)
                    st.session_state["messages_doc"].append({"role": "assistant", "content": answer})

    # --- Tab 3: æ–°å“ç ”å‘ ---
    with tab3:
        st.subheader("ğŸ’¡ æ–°å“æ¦‚å¿µç”Ÿæˆ")
        c1, c2 = st.columns(2)
        with c1: base_product = st.text_input("åŸºåº•", "0ç³–é…¸å¥¶")
        with c2: target_user = st.text_input("äººç¾¤", "å‡è„‚å…š")
        trend = st.selectbox("è¶‹åŠ¿", ["è¯é£ŸåŒæº", "0ç³–0å¡", "é«˜è›‹ç™½"])
        
        if st.button("ç”Ÿæˆ"):
            # æ¦‚å¿µç”Ÿæˆä¸éœ€è¦ R1ï¼Œç”¨ V3 å³å¯ï¼Œçœé’±ä¸”å¿«
            col_text, col_chart = st.columns([3, 2])
            with col_text: 
                # è¿™é‡Œè°ƒç”¨ once é»˜è®¤æ˜¯ chat æ¨¡å‹
                st.markdown(call_deepseek_once("ç”Ÿæˆæ¦‚å¿µä¹¦", f"{base_product} {target_user} {trend}"))
            with col_chart: 
                st.plotly_chart(plot_sensory_radar(base_product, trend))

# ==================================================
# æ¨¡å— 2: è‡ªåª’ä½“ (ä¿æŒ V3.1)
# ==================================================
elif app_mode == "ğŸ¬ è‡ªåª’ä½“å†…å®¹çŸ©é˜µ":
    st.title("ğŸ¬ è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿäº§å·¥å‚")
    tab_script, tab_voice = st.tabs(["ğŸ“ æ™ºèƒ½è„šæœ¬ç”Ÿæˆ", "ğŸ™ï¸ AI é…éŸ³å®¤ (TTS)"])

    with tab_script:
        col_hot, col_gen = st.columns([1, 2])
        with col_hot:
            if st.button("ğŸ”„ åˆ·æ–°çƒ­æœ"): st.cache_data.clear()
            hot_list = get_realtime_news()
            selected_hot = st.radio("é€‰æ‹©çƒ­ç‚¹ï¼š", hot_list, index=None)
            if selected_hot: st.session_state['selected_topic'] = selected_hot

        with col_gen:
            topic = st.text_input("é€‰é¢˜", value=st.session_state.get('selected_topic', ''))
            c1, c2 = st.columns(2)
            with c1: type_ = st.selectbox("ç±»å‹", ["è¾Ÿè°£", "æµ‹è¯„", "æ­ç§˜"])
            with c2: style = st.selectbox("é£æ ¼", ["å®æ‹", "åŠ¨æ¼«", "èµ›åš"])
            if st.button("ğŸš€ ç”Ÿæˆåˆ†é•œè„šæœ¬"):
                if topic:
                    st.info("ğŸ’¡ æç¤ºï¼šè¯·å¤åˆ¶æ–‡æ¡ˆåˆ°é…éŸ³å®¤ä½¿ç”¨ã€‚")
                    prompt = f"æˆ‘æ˜¯ç§‘æ™®åšä¸»ã€‚é€‰é¢˜ï¼š{topic}ã€‚ç±»å‹ï¼š{type_}ã€‚é£æ ¼ï¼š{style}ã€‚è¾“å‡ºMarkdownåˆ†é•œè¡¨ã€‚"
                    st.markdown(call_deepseek_once(prompt, topic))

    with tab_voice:
        st.subheader("ğŸ™ï¸ AI é…éŸ³å®¤")
        text_input = st.text_area("ç²˜è´´æ–‡æ¡ˆ", height=150)
        voice_option = st.selectbox("é€‰æ‹©éŸ³è‰²", ["zh-CN-YunxiNeural (ç”·å£°)", "zh-CN-XiaoxiaoNeural (å¥³å£°)"])
        if st.button("ğŸ§ ç”Ÿæˆè¯­éŸ³"):
            if text_input:
                try:
                    mp3 = asyncio.run(generate_speech(text_input, voice_option.split(" ")[0]))
                    st.audio(mp3, format="audio/mp3")
                    st.success("ç”ŸæˆæˆåŠŸ")
                except Exception as e: st.error(f"å¤±è´¥: {e}")

# ==================================================
# æ¨¡å— 3: äº‘ç«¯çœ‹æ¿
# ==================================================
elif app_mode == "âš™ï¸ äº‘ç«¯æ•°æ®çœ‹æ¿":
    st.title("âš™ï¸ è‡ªåŠ¨åŒ–ç³»ç»Ÿç›‘æ§")
    st.info("äº‘ç«¯ä»»åŠ¡ï¼šdaily_task.py æ­£åœ¨ GitHub æœåŠ¡å™¨ä¸Šæ¯æ—¥ 08:00 è¿è¡Œ")
    if st.button("ğŸ“² å‘é€æµ‹è¯•æ¨é€"):
        if "BARK_SERVER" in st.secrets:
            try:
                requests.get(f"{st.secrets['BARK_SERVER']}/{st.secrets['BARK_DEVICE_KEY']}/æµ‹è¯•/ç½‘é¡µç«¯æŒ‡ä»¤")
                st.success("âœ… æ¨é€æˆåŠŸ")
            except: st.error("å¤±è´¥")